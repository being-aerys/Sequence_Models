{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms_package\n",
    "torch.set_printoptions(linewidth = 120)\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ETL : Extract from source, Transform into a proper tensor, Load as an object\n",
    "\n",
    "#torchvision package gives us access to the links of different datasets that are available online\n",
    "training_data = torchvision.datasets.MNIST(root = \"../datasets/mnist\",train = True, download = True, transform = transforms_package.Compose([transforms_package.ToTensor()]))\n",
    "\n",
    "#load this extracted data into a DataLoader object\n",
    "data_loader = torch.utils.data.DataLoader(training_data, batch_size = 10) #note that we have already defined the batch size here\n",
    "\n",
    "#now, each enumeration of data_loader contains 10 samples\n",
    "\n",
    "#print(len(data_loader)) prints 6k not 60k since each data_loader enumeration has 10 samples\n",
    "\n",
    "#to get the testing data, put the argument as train = False\n",
    "testing_data = torchvision.datasets.MNIST(root = \"../datasets/mnist_test\",train = False, download = True, transform = transforms_package.Compose([transforms_package.ToTensor()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 3 # can make it more than three but this model already converges in the second epoch\n",
    "#can make data iteratble as batch = next(iter(data_loader)) so that the network can take a batch at a time\n",
    "#print(batch)\n",
    "\n",
    "#Steps for a NN implementaiton\n",
    "#1.Extend the nn.module base class\n",
    "#2.In the class constructor, Define layers as class attributes\n",
    "#3.Use the network's layer attributes (as well as operations fron nn.functional api) to define the network's different layers' structure\n",
    "#4.Implement the forward() method\n",
    "\n",
    "\n",
    "#to build a NN, we import a torch.nn package\n",
    "#Within in the nn package, there is a class called a module which is a base class for all nn modules\n",
    "#all layers in pytorch extend the nn.Module class and inherit the attributes and functions\n",
    "#this is called inhertitance\n",
    "#with this inheritance, we get all the NN layers and the neural network as a whole\n",
    "#why do we extend the layers and the whole network from a single class\n",
    "#because the whole network can be assumed to be one large layer\n",
    "#since the layers are essentially functions and the NN is a collection of functions ==> a funciton itself, this similarity is captured by the n.Module class in the libreary\n",
    "#thus we extend the nn.Module class if we want a new NN or a new layer withihn that NN \n",
    "#usually all neurons in a single layer are of the same type of neuron, so we define just 1 forward activation funciton and one weights tensor for the whole layer\n",
    "#each layer has its own transformation and the composition of the forward pass\n",
    "#thus every pytorch NN module/ Neural Noetwork has a forward method that represents the forward pass of the network as a whole\n",
    "#when implementing the forward method, we use functions from nn.functional package that contains the activation, has an in-built a activation to which we just have to provide the input and the weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#each of the layer extends nn.modules class TORCH.NN.MODULES behind the scenes\n",
    "#In reality, the actual definition given for a model in TORCH.NN.MODULES has the form==> class Linear(Module):\n",
    "\n",
    "# class Module(object):\n",
    "#        Base class for all neural network modules.\n",
    "\n",
    "#        Your models should also subclass this class.\n",
    "\n",
    "#     Modules can also contain other Modules, allowing to nest them in\n",
    "#     a tree structure. You can assign the submodules as regular attributes::\n",
    "\n",
    "#         import torch.nn as nn\n",
    "#         import torch.nn.functional as F\n",
    "\n",
    "#         class Model(nn.Module):\n",
    "#             def __init__(self):\n",
    "#                 super(Model, self).__init__()\n",
    "#                 self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "#                 self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "#             def forward(self, x):\n",
    "#                x = F.relu(self.conv1(x))\n",
    "#                return F.relu(self.conv2(x))\n",
    "\n",
    "#     Submodules assigned in this way will be registered, and will have their\n",
    "#     parameters converted too when you call :meth:`to`, etc.\n",
    "\n",
    "\n",
    "#you want to create a class that represents the NN as a whole and has all the layers as attributes \n",
    "#also, you want to implement a forward method that defines the forward propagation in your network\n",
    "\n",
    "\n",
    "#Module bhanne class xa modules bhanne package bhitra Linear, Convolution named classes haru sangai \n",
    "#nn.Module has a forward function jun hamro layer le ra network as a whole le  implement garnu parxa\n",
    "#But while we explicitly define a forward function for the network, we just provide certain required parameters needed for each layer instead of defining the forward() method ourself for each layer\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "class Network_dummy(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.layer = None #single dummy layer inside the constructure\n",
    "     \n",
    "    def forward_propagation_demo(self, t): #dummy forward funciton takes in a tensor t ahnd tranforms it using the dummy layer\n",
    "        \n",
    "        return self.layer(t) #operation iong the input tenso t\n",
    "    \n",
    "    \n",
    "        \n",
    "class Network(nn.Module): \n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__() #initializes using the super class nn.Module, define layers as attributes\n",
    "        \n",
    "        #Linear and Conv2d classes extend the Module class thats why all the attrbutes that we have have a set of weights and a forward funciton of their own by default as inhetiance\n",
    "        \n",
    "        #parameters are subclasses that have a special property when used with Module class \n",
    "        #IMP : when assigned as class attribuites, they are automatically added as parameters of the module\n",
    "        \n",
    "      \n",
    "        #kernel = filter, convolutional kernel = convolutional filter\n",
    "        #out_channels = Number of filters to use in this layer\n",
    "        #out_features (for linear layers) = Size of the output tensor for this linear layer, if it is the  last layer, it is kinda fixed already though        \n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #How many hidden neurons to use? The no of the output neurons should be less than the no of input neurons, thus, the no of hideen neurns should be lss than the inpout nbeurons\n",
    "        \n",
    "        #This is how you flattten a batch of input to feed into a fully-connected layer in batch processing\n",
    "        # You make a pair (batch_size, flattened tensor of each image)\n",
    "        #Say if the image is 28*28 and has 3 channels from the previous layer then\n",
    "        #(batch_size, 3 * 28*28) is the shape of the input to the fully connected layer\n",
    "        #there will be 3*28*28 neurons in this fully-connected layer\n",
    "        #the no of output channels for this layer is actually the total no of neurons that will be present in the next layer\n",
    "        \n",
    "        \n",
    "        \n",
    "        #where did the  8 * 8 come from?#that is the length of the flattened tensor from the previous layer\n",
    "\n",
    "        self.fully_connected1 = nn.Linear(in_features = 12 * 8 * 8, out_features = 120)\n",
    "        self.fully_connected2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.output_layer = nn.Linear(in_features = 60, out_features = 10)\n",
    "        \n",
    "    \n",
    "        \n",
    "        #usually, with a conv layer, we increase the size of the out channels\n",
    "        #with a linear layer, we decrease\n",
    "        #each of the layers should have a set of weights and the definition for the forward function\n",
    "        #Since we are extending Module class, each of them has a set of weight and a forward function already defined in the definiotion of Module\n",
    "        #nn Module keeps track of the weight tensors in each layer  and by extending the Module , we inherit the functionality automatially\n",
    "        \n",
    "    def flat_features_except_batch(self, x):\n",
    "        size = x.size()[1:]  #flatten all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:       # Get the products\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def forward(self, t): #dummy forward funciton takes in a tensor t ahnd tranforms it using the dummy layer\n",
    "        out = self.conv1(t)\n",
    "        #print(out[0])\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.conv2(out)\n",
    "        #print(out.data.shape)\n",
    "        out = out.view(-1, self.flat_features_except_batch(out))\n",
    "        #print(out.shape)\n",
    "        out = self.fully_connected1(out)\n",
    "        out = self.fully_connected2(out)\n",
    "        #print(out.size)\n",
    "        out = self.output_layer(out)\n",
    "        #print(\"final output ko shape yesto \")\n",
    "        #print(out.size)\n",
    "        return out #final output of the network\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fully_connected1): Linear(in_features=768, out_features=120, bias=True)\n",
      "  (fully_connected2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (output_layer): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#you can use padding as an argument to preserve the original size of the height and the width of the data after it decreases because of the convolution\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "network = Network()# \n",
    "print(network)\n",
    "# print(network.conv1)\n",
    "# print(network.conv1.weight)\n",
    "#weight is an instance of Parameter class that extends tensor.Tensor class and represents the learnable parameters of each layer\n",
    "#print(network.conv1.weight.shape) #this returns the tensor that represents all the filters of this conv layer\n",
    "#we can access a single filter as network.conv2.weight[0]\n",
    "#weight of a convolution filter is the filter itself \n",
    "#define the loss function you want to use for your network, provided in torch.optim package\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual operation of CNN\n",
    "\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(epochs): \n",
    "    print(\"data loader size  shape is : \",len(data_loader))\n",
    "    for i, (features, labels) in enumerate (data_loader): #enumerate indexes a list of tuples to make looping easier\n",
    "        \n",
    "        print(\"training count is \",i)\n",
    "        print(\"\\n\\n\")\n",
    "        total_correct_predictions = 0\n",
    "        \n",
    "        \n",
    "    #     print(\"Input shape is : \")\n",
    "    #     print(features.shape)\n",
    "    #     print(\"labels shape is :\")\n",
    "    #     print (labels.shape)\n",
    "    #     print(labels.data)\n",
    "    \n",
    "    \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        #print(\"features shape \",features.shape)\n",
    "        \n",
    "        # Forward propagation\n",
    "        train_pass = features.view(10,1,28,28)\n",
    " \n",
    "        final_output = network(train_pass) #network operation\n",
    "    \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = loss_fn(final_output, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        \n",
    "        ###################EVERY 100 iterations###########################\n",
    "        if (count +1)%100 ==0:\n",
    "            correct = 0\n",
    "            incorrect = 0\n",
    "            total=0\n",
    "            test_count = 0\n",
    "            for (test_features, labels) in testing_data:\n",
    "                test_count = test_count+1\n",
    "                print(\"test count \",test_count)\n",
    "                #print(\"test_features size \",len(testing_data))\n",
    "                test = test_features.view(1,1,28,28)\n",
    "                output = network(test)\n",
    "                _,predicted = torch.max(output.data,1)\n",
    "                #print(\"here \" ,labels.data)\n",
    "                #print(\"predicted and labels.data\")\n",
    "#                 print(\"predicted is\", predicted.data)\n",
    "#                 print(\"label is \",labels.data)\n",
    "#                 print(\" equality check \",(predicted == labels.data).sum())\n",
    "                correct += (predicted == labels.data).sum()\n",
    "                #print(\"correct is \",correct.data)\n",
    "           \n",
    "            accuracy = 100 *correct/float(10000)\n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "            print('Iteration Number : {}, Training Loss: {}, Testing Accuracy: {}%'.format(count,loss.data,accuracy))\n",
    "        \n",
    "        ######################################################################\n",
    "          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of the training loss \n",
    "\n",
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Loss vs Number of iterations\")\n",
    "plt.show()\n",
    "\n",
    "# visualization of the accuracy \n",
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs Number of iteration\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
